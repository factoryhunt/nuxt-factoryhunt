input {
    jdbc {
        # MySQL Connection
        jdbc_connection_string => "jdbc:mysql://fh-rds.cfwdgkhtxdcy.us-west-1.rds.amazonaws.com:3306/fh"
        jdbc_user => "YOUR_USER"
        jdbc_password => "YOUR_PASSWORD"

        # JDBC Driver
        jdbc_driver_library => "/home/ubuntu/elastic/logstash/plugins/mysql-connector-java-5.1.38.jar"
        jdbc_driver_class => "com.mysql.jdbc.Driver"
        jdbc_pool_timeout => 3000

        # Query Setting
        # it allows JDBC to use built-in property "sql_last_value"
        # default value is timestamp, but you can set what you want.
        # if you need, configure "use_column_value" and "tracking_column"
        use_column_value => true
        tracking_column => lead_id

        # Query
        statement =>
        "
        SELECT
        lead_id,
        company,
        lead_status,
        lead_type,
        domain,
        products,
        company_description,
        website,
        phone,
        mailing_country,
        last_modified_date
        FROM
        leads
        "

        # Schedule data mapping every minute.
        # schedule => "* * * * *"
    }
}

filter {
    mutate { rename => {"lead_id" => "account_id"} }
    mutate { rename => {"lead_type" => "account_type"} }
    mutate { rename => {"company" => "account_name"} }
    mutate { rename => {"lead_status" => "account_status"} }
}

output {
    stdout { codec => rubydebug }
    elasticsearch {
        # Host
        hosts => ["localhost:9200"]

        # ES index name
        index => "es-leads"

        # this configuration resolve data duplication issue.
        document_id => "%{account_id}"
    }
}
